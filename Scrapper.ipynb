{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662dca41-5319-48be-9a40-73074a68ebe7",
   "metadata": {},
   "source": [
    "# Premier League Data Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70356df-846d-484f-9d97-c09ab06f72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import lxml\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a293f5fc-6ddd-46b5-aebd-0a597e2df81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url     = \"https://free-proxy-list.net/\"\n",
    "test_ip = \"http://icanhazip.com\"\n",
    "###  get the HTTP response and construct soup object\n",
    "r       = requests.get(url)\n",
    "soup    = bs(r.content, \"html.parser\")\n",
    "table   = soup.find(\"table\", attrs = {\"class\": \"table table-striped table-bordered\"})#.prettify()\n",
    "\n",
    "proxies   = []\n",
    "anonymity = []\n",
    "lim       = 123\n",
    "\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5da2fc-718e-4a5e-b31a-59c43ee9084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prem_data          = []\n",
    "wins               = []\n",
    "losses             = []\n",
    "touches            = []\n",
    "own_goals          = []\n",
    "yellow_cards       = []\n",
    "red_cards          = []\n",
    "goals              = []\n",
    "passes             = []\n",
    "scoring_attacks    = []\n",
    "offsides           = []\n",
    "woodwork           = []\n",
    "chances_missed     = []\n",
    "tackles            = []\n",
    "clearances         = []\n",
    "clearance_off_line = []\n",
    "dispossessed       = []\n",
    "clean_sheet        = []\n",
    "saves              = []\n",
    "penalty_saves      = []\n",
    "high_claim         = []\n",
    "punches            = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "482cbee2-94cd-4a58-8e03-fa28bd0ccb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "    ''''''' A function that cleans html code from a proxy websites table, to extracts three variables: Ip_Address + Port, and Anonymity (the type of proxy) '''''''\n",
    "    \n",
    "    for row in table.find_all(\"tr\")[1:]:\n",
    "        td = row.find_all(\"td\")\n",
    "        try:\n",
    "            ip_address = td[0].text.strip()\n",
    "            port      = td[1].text.strip()\n",
    "            host      = f\"{ip_address}:{port}\"\n",
    "            proxies.append(host)\n",
    "            \n",
    "            anon      = td[4].text\n",
    "            anonymity.append(anon)\n",
    "\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return proxies, anonymity\n",
    "\n",
    "\n",
    "def organise_data():\n",
    "    ''''''' A function to sort through scrapped data from prempier league web pages. '''''''\n",
    "    \n",
    "    titles = prem_soup.find_all(\"div\", attrs = {\"data-metric\"}) \n",
    "    prem_tables = prem_soup.find(\"table\")\n",
    "    \n",
    "    for row in prem_tables.find_all(\"tr\"):\n",
    "        tr = row.find_all(\"tr\")\n",
    "        # wins ## 16 tr\n",
    "        if row == tr[0:16]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            wins_title = titles[0].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            win_data = f\"{wins_title}:{name}:{stat}\"\n",
    "            wins.append(win_data)\n",
    "        # loses ## 19 tr \n",
    "        elif row == tr[16:35]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            loses_title = titles[1].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            loses_data = f\"{loses_title}:{name}:{stat}\"\n",
    "            loses.append(loses_data)\n",
    "        # touches ## 20 tr\n",
    "        elif row == tr[35:55]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            touches_title = titles[2].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            touches_data = f\"{touches_title}:{name}:{stat}\"\n",
    "            touches.append(touches_data)\n",
    "        # own_goals ## 7 tr\n",
    "        elif row == tr[55:62]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            own_goals_title = titles[3].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            own_goals_data = f\"{own_goals_title}:{name}:{stat}\"\n",
    "            own_goals.append(own_goals_data)\n",
    "        # yellow cards ## 20 tr\n",
    "        elif row == tr[62:82]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            yellow_cards_title = titles[4].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            yellow_cards_data = f\"{yellow_cards_title}:{name}:{stat}\"\n",
    "            yellow_cards.append(yellow_cards_data)\n",
    "        # red cards ## 9 tr\n",
    "        elif row == tr[82:91]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            red_cards_title = titles[5].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            red_cards_data = f\"{red_cards_title}:{name}:{stat}\"\n",
    "            red_cards.append(red_cards_data)\n",
    "        # goals ## 20\n",
    "        elif row == tr[91:111]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            goals_title = titles[6].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            goals_data = f\"{goals_title}:{name}:{stat}\"\n",
    "            goals.append(goals_data)\n",
    "        # passes ## 20\n",
    "        elif row == tr[111:131]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            passes_title = titles[7].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            passes_data = f\"{passes_title}:{name}:{stat}\"\n",
    "            passes.append(passes_data)\n",
    "        # scoring_attacks ## 20\n",
    "        elif row == tr[131:151]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            scoring_attacks_title = titles[8].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            scoring_attacks_data = f\"{scoring_attacks_title}:{name}:{stat}\"\n",
    "            scoring_attacks.append(scoring_attacks_data)\n",
    "        # offsides ## 20\n",
    "        elif row == tr[151:171]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            offsides_title = titles[9].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            offsides_data = f\"{offsides_title}:{name}:{stat}\"\n",
    "            offsides.append(offsides_data)\n",
    "        # woodwork ## 15\n",
    "        elif row == tr[171:186]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            woodwork_title = titles[10].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            woodwork_data = f\"{woodwork_title}:{name}:{stat}\"\n",
    "            woodwork.append(woodwork_data) \n",
    "        # chances_missed ## 20\n",
    "        elif row == tr[186:206]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            chances_missed_title = titles[11].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            chances_missed_data = f\"{chances_missed_title}:{name}:{stat}\"\n",
    "            chances_missed.append(chances_missed_data)\n",
    "        # tackles ## 20\n",
    "        elif row == tr[206:226]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            tackles_title = titles[12].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            tackles_data = f\"{tackles_title}:{name}:{stat}\"\n",
    "            tackles_cards.append(tackles_data) \n",
    "        # clearances ## 20\n",
    "        elif row == tr[226:246]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            clearances_title = titles[13].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            clearances_data = f\"{clearances_title}:{name}:{stat}\"\n",
    "            clearances.append(clearances_data) \n",
    "        # clearance_off_line ## 14\n",
    "        elif row == tr[246:260]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            clearance_off_line_title = titles[14].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            clearance_off_line_data = f\"{clearance_off_line_title}:{name}:{stat}\"\n",
    "            clearance_off_line.append(clearance_off_line_data)\n",
    "        # dispossessed ## 20\n",
    "        elif row == tr[260:280]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            dispossessed_title = titles[15].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            dispossessed_data = f\"{dispossessed_title}:{name}:{stat}\"\n",
    "            dispossessed.append(dispossessed_data)\n",
    "        # clean_sheet ## 18\n",
    "        elif row == tr[280:298]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            clean_sheet_title = titles[16].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            clean_sheet_data = f\"{clean_sheet_title}:{name}:{stat}\"\n",
    "            clean_sheet.append(clean_sheet_data)\n",
    "        # saves ## 20\n",
    "        elif row == tr[298:318]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            saves_title = titles[17].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            saves_data = f\"{saves_title}:{name}:{stat}\"\n",
    "            saves.append(saves_data)\n",
    "        # penalty_saves  ## 2\n",
    "        elif row == tr[318:320]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            penalty_saves_title = titles[18].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            penalty_saves_data = f\"{penalty_saves_title}:{name}:{stat}\"\n",
    "            penalty_saves.append(penalty_saves_data)\n",
    "        # high_claim   ## 20\n",
    "        elif row == tr[320:340]:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            high_claim_title = titles[19].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            high_claim_data = f\"{high_claim_title}:{name}:{stat}\"\n",
    "            high_claim.append(high_claim_data)\n",
    "        # punches   ## 16\n",
    "        else:\n",
    "            \n",
    "            td   = row.find_all(\"td\")\n",
    "            punches_title = titles[20].text\n",
    "            name = td[1].text\n",
    "            stat = td[2].text.strip()\n",
    "            \n",
    "            punches_data = f\"{punches_title}:{name}:{stat}\"\n",
    "            punches.append(punches_data)\n",
    "\n",
    "    return wins, losses, touches, own_goals, yellow_cards, red_cards, goals, passes, scoring_attacks, offsides, woodwork, chances_missed, tackles, clearances, clearance_off_line, dispossessed, clean_sheet, saves, penalty_saves, high_claim, punches\n",
    "    \n",
    "# wins \n",
    "\n",
    "# example 1:\n",
    "# <body>\n",
    "#  <main id=\"mainContent\" tabindex=\"0\">\n",
    "#   <div class=\"hasSideNav\">\n",
    "#    <div class=\"sidebarPush\">\n",
    "#     <div class=\"col-12\">\n",
    "#      <div data-script=\"pl_stats\" data-widget=\"stats-table\" data-stat=\"wins\" data-current-size=\"20\" data-type=\"team\" data-page-size=\"20\" data-page=\"0\" data-comps=\"1\" data-num-entries=\"50\">\n",
    "#       <div class=\"dropDown noLabel topStatsFilterDropdown\" data-listener=\"true\">\n",
    "###       <div data-metric=\"wins\" class=\"current currentStatContainer\" role=\"button\">\n",
    "#       <div class=\"table playerIndex statsTable teamStatsTable\">\n",
    "#        <table>\n",
    "#         <tbody class=\"statsTableContainer\">\n",
    "#          <tr class>\n",
    "#           <td> ## td[1]\n",
    "###          <a href=\"//www.premierleague.com/clubs/4/club/overview\" class=\"playerName\">\n",
    "#           </td>\n",
    "###         <td class=\"mainStat text-centre\">5</td> ## td[2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615d6ca7-5b81-4b19-ad34-a3bfd78c4656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status OK, for proxy: 139.99.149.94\n",
      "\n",
      "Status OK, for proxy: 203.190.118.22\n",
      "\n",
      "Status OK, for proxy: 103.66.196.218\n",
      "\n",
      "Status OK, for proxy: 177.73.149.250\n",
      "\n",
      "Status OK, for proxy: 190.196.176.5\n",
      "\n",
      "Status OK, for proxy: 59.153.83.170\n",
      "\n",
      "Status OK, for proxy: 181.224.204.22\n",
      "\n",
      "Status OK, for proxy: 41.217.219.53\n",
      "\n",
      "Status OK, for proxy: 3.140.254.145\n",
      "\n",
      "Status OK, for proxy: 52.87.240.197\n",
      "\n",
      "Status OK, for proxy: 186.219.96.47\n",
      "\n",
      "Status OK, for proxy: 81.24.93.176\n",
      "\n",
      "Status OK, for proxy: 202.158.15.146\n",
      "\n",
      "Status OK, for proxy: 81.24.117.250\n",
      "\n",
      "Status OK, for proxy: 167.99.248.92\n",
      "\n",
      "Status OK, for proxy: 103.217.179.185\n",
      "\n",
      "Status OK, for proxy: 169.57.1.84\n",
      "\n",
      "Status OK, for proxy: 103.205.183.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_proxies()\n",
    "\n",
    "proxy_data = {'proxies':proxies,'anonymity':anonymity}\n",
    "proxy_df = pd.DataFrame(proxy_data) ## create data frame of proxy data\n",
    "\n",
    "pd.set_option('display.max_columns',100) ## adjusting pandas display settings\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.width',1000)\n",
    "# print(proxy_df[:5])\n",
    "\n",
    "\n",
    "anonymity = proxy_df.loc[proxy_df ['anonymity'] == 'elite proxy'] ### creating a new dataframe with only elite proxies\n",
    "\n",
    "elite_prox = [row for row in anonymity['proxies']] ## list comprehension to separate proxies\n",
    "\n",
    "for proxy in elite_prox:\n",
    "    s1       = requests.Session()\n",
    "    try:\n",
    "        page = s1.get(test_ip, proxies={\"http\": proxy, \"https\": proxy}, timeout = 1.5)\n",
    "        print(\"Status OK, for proxy:\", page.text)\n",
    "    \n",
    "    except OSError as e:\n",
    "        elite_prox.remove(proxy)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9aea0dc-05e5-4103-886f-ce56fea0af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(elite_prox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d19b4-a520-44f5-9ed2-d93e9cc39e93",
   "metadata": {},
   "source": [
    "### Load the page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788db994-0388-4c66-a12a-52b8a0fe59af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Status OK, found: losses \n",
      "2.Status OK, found: touches \n",
      "3.Status OK, found: own_goals \n",
      "3.Status OK, found: own_goals \n",
      "5.Status OK, found: total_red_card \n",
      "6.Status OK, found: goals \n",
      "7.Status OK, found: total_pass \n",
      "10.Status OK, found: hit_woodwork \n",
      "10.Status OK, found: hit_woodwork \n",
      "11.Status OK, found: big_chance_missed \n",
      "11.Status OK, found: big_chance_missed \n",
      "11.Status OK, found: big_chance_missed \n",
      "15.Status OK, found: dispossessed \n",
      "17.Status OK, found: saves \n",
      "18.Status OK, found: penalty_save \n",
      "18.Status OK, found: penalty_save \n",
      "18.Status OK, found: penalty_save \n",
      "19.Status OK, found: total_high_claim \n",
      "20.Status OK, found: punches \n",
      "20.Status OK, found: punches \n"
     ]
    }
   ],
   "source": [
    "pages=['wins', 'losses', 'touches', 'own_goals', 'total_yel_card', 'total_red_card', 'goals','total_pass', 'total_scoring_att', 'total_offside', 'hit_woodwork', 'big_chance_missed', 'total_tackle', 'total_clearance','clearance_off_line', 'dispossessed', 'clean_sheet', 'saves', 'penalty_save', 'total_high_claim', 'punches']\n",
    "\n",
    "for i, title in enumerate(pages):\n",
    "    try:\n",
    "        \n",
    "        prem_url = \"https://www.premierleague.com/stats/top/clubs/{}?se=418\".format(pages[i])\n",
    "        s2       = requests.Session()\n",
    "    \n",
    "        for k in elite_prox:\n",
    "            \n",
    "            prem_r = s2.get(prem_url, proxies = {\"http\": k, \"https\": k})\n",
    "            prem_soup = bs (prem_r.content, \"lxml\") ## Convert to soup\n",
    "            prem_data.append(prem_soup)\n",
    "            print(\"{}.Status OK, found: {} \".format(i, pages[i]))\n",
    "        \n",
    "    except OSError as e:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94da7bee-4e8f-4eb6-94e4-217d49e1a59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17132/3034671068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(prem_divs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0morganise_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# prem_data = {'wins': wins, 'losses': losses, 'own goals': own_goals, 'yellow cards': total_yel_card, 'red cards': total_red_card, 'goals scored': goals, 'passes': total_pass, 'scoring attacks':total_scoring_att, 'offsides':total_offside, 'woodwork':hit_woodwork, 'misses':big_chance_missed, 'tackles':total_tackle, 'clearance':total_clearance, 'off the line':clearance_off_line, 'lost the ball':dispossessed, 'clean sheeets':clean_sheet, 'saves':saves, 'penalty saves':penalty_save, 'keeper possession':total_high_claim, 'fights':punches}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17132/744196909.py\u001b[0m in \u001b[0;36morganise_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mtd\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"td\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mpunches_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prem_divs = prem_soup.findAll(\"div\", attrs = {\"class\":\"col-12\"})\n",
    "#print(prem_divs)\n",
    "\n",
    "organise_data()\n",
    "\n",
    "# prem_data = {'wins': wins, 'losses': losses, 'own goals': own_goals, 'yellow cards': total_yel_card, 'red cards': total_red_card, 'goals scored': goals, 'passes': total_pass, 'scoring attacks':total_scoring_att, 'offsides':total_offside, 'woodwork':hit_woodwork, 'misses':big_chance_missed, 'tackles':total_tackle, 'clearance':total_clearance, 'off the line':clearance_off_line, 'lost the ball':dispossessed, 'clean sheeets':clean_sheet, 'saves':saves, 'penalty saves':penalty_save, 'keeper possession':total_high_claim, 'fights':punches}\n",
    "# df = pd.DataFrame(prem_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f47d4-af39-4a25-9b00-b4df405ab2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
